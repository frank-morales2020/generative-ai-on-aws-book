{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/generative-ai-on-aws-book/blob/main/01_langchain_llama2_sagemaker-frankmorales-version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36e85f55-9a35-4d97-9917-bef3f6e8a627",
      "metadata": {
        "id": "36e85f55-9a35-4d97-9917-bef3f6e8a627"
      },
      "source": [
        "# Retrieval Augmented Generation (RAG) with LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89353535-16f4-438a-8613-be3d698f0a96",
      "metadata": {
        "id": "89353535-16f4-438a-8613-be3d698f0a96"
      },
      "source": [
        "In this example notebook, you will see how to perform basic Retrieval Augmented Generation (RAG) using a collection of Amazon's Letters to Shareholders to run basic Q&A.\n",
        "\n",
        "This notebook does not have any specific CPU/GPU requirements, and was built using the `Data Science 3.0 Python 3` kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1335cbce-a8a6-443d-804b-c6bc4d0d8c54",
      "metadata": {
        "tags": [],
        "id": "1335cbce-a8a6-443d-804b-c6bc4d0d8c54"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4174bd3f-7ea6-4e40-9617-a7d263cc0f11",
      "metadata": {
        "id": "4174bd3f-7ea6-4e40-9617-a7d263cc0f11"
      },
      "source": [
        "Install the dependencies for this example:\n",
        "- LangChain: Framework for Orchestrating the RAG workflow\n",
        "- FAISS: In-Memory Vector Database for storing document embeddings\n",
        "- PyPDF: Python library for processing PDF documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "34e49456-bad8-40b3-b266-87a3935f7aeb",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34e49456-bad8-40b3-b266-87a3935f7aeb",
        "outputId": "c2b50fb3-571e-4240-c6d4-baa556d5fc2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.0/271.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install langchain==0.0.309 --quiet --root-user-action=ignore\n",
        "%pip install faiss-cpu==1.7.4 --quiet --root-user-action=ignore\n",
        "%pip install pypdf==3.15.1 --quiet --root-user-action=ignore"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/generative-ai-on-aws/generative-ai-on-aws/tree/main\n",
        "#!pip install --upgrade pip\n",
        "\n",
        "\n",
        "!pip install colab-env --upgrade\n",
        "\n",
        "import colab_env\n",
        "import os\n",
        "\n",
        "\n",
        "aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "region=os.getenv(\"region\")\n",
        "output=os.getenv(\"output\")\n",
        "\n",
        "#print(aws_access_key_id)\n",
        "#print()\n",
        "#print(f\"aws_access_key_id: ('{aws_access_key_id}')\")\n",
        "#print(f\"aws_secret_access_key: ('{aws_secret_access_key}')\")\n",
        "#print()\n",
        "\n",
        "#!pip install aws configure\n",
        "#!pip install awscli\n"
      ],
      "metadata": {
        "id": "qsQb50EopMQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47192210-8552-496b-ebd7-ce305e8a877b"
      },
      "id": "qsQb50EopMQS",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colab-env\n",
            "  Downloading colab-env-0.2.0.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-dotenv<1.0,>=0.10.0 (from colab-env)\n",
            "  Downloading python_dotenv-0.21.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: colab-env\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colab-env: filename=colab_env-0.2.0-py3-none-any.whl size=3805 sha256=1bd098e614521653d0658c2ce6a1457da623a032193e12a43d17afc87604bf1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/36/4f/466c2cd4db5d08f317893a920c4a0f58a81459ee3bdb136d35\n",
            "Successfully built colab-env\n",
            "Installing collected packages: python-dotenv, colab-env\n",
            "Successfully installed colab-env-0.2.0 python-dotenv-0.21.1\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nLZgmSOS_dG",
        "outputId": "8ab25760-ead2-4aed-9528-48f310647d20"
      },
      "id": "5nLZgmSOS_dG",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "aiohttp                          3.9.1\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.13\n",
            "albumentations                   1.3.1\n",
            "altair                           4.2.2\n",
            "anyio                            3.7.1\n",
            "appdirs                          1.4.4\n",
            "argon2-cffi                      23.1.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array-record                     0.5.0\n",
            "arviz                            0.15.1\n",
            "astropy                          5.3.4\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.3\n",
            "atpublic                         4.0\n",
            "attrs                            23.1.0\n",
            "audioread                        3.0.1\n",
            "autograd                         1.6.2\n",
            "Babel                            2.14.0\n",
            "backcall                         0.2.0\n",
            "beautifulsoup4                   4.11.2\n",
            "bidict                           0.22.1\n",
            "bigframes                        0.17.0\n",
            "bleach                           6.1.0\n",
            "blinker                          1.4\n",
            "blis                             0.7.11\n",
            "blosc2                           2.0.0\n",
            "bokeh                            3.3.2\n",
            "bqplot                           0.12.42\n",
            "branca                           0.7.0\n",
            "build                            1.0.3\n",
            "CacheControl                     0.13.1\n",
            "cachetools                       5.3.2\n",
            "catalogue                        2.0.10\n",
            "certifi                          2023.11.17\n",
            "cffi                             1.16.0\n",
            "chardet                          5.2.0\n",
            "charset-normalizer               3.3.2\n",
            "chex                             0.1.7\n",
            "click                            8.1.7\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.27.9\n",
            "cmdstanpy                        1.2.0\n",
            "colab-env                        0.2.0\n",
            "colorcet                         3.0.1\n",
            "colorlover                       0.3.0\n",
            "colour                           0.1.5\n",
            "community                        1.0.0b1\n",
            "confection                       0.1.4\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.2.0\n",
            "cryptography                     41.0.7\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda12x                     12.2.0\n",
            "cvxopt                           1.3.2\n",
            "cvxpy                            1.3.2\n",
            "cycler                           0.12.1\n",
            "cymem                            2.0.8\n",
            "Cython                           3.0.6\n",
            "dask                             2023.8.1\n",
            "dataclasses-json                 0.6.3\n",
            "datascience                      0.17.6\n",
            "db-dtypes                        1.2.0\n",
            "dbus-python                      1.2.18\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "diskcache                        5.6.3\n",
            "distributed                      2023.8.1\n",
            "distro                           1.7.0\n",
            "dlib                             19.24.2\n",
            "dm-tree                          0.1.8\n",
            "docutils                         0.18.1\n",
            "dopamine-rl                      4.0.6\n",
            "duckdb                           0.9.2\n",
            "earthengine-api                  0.1.384\n",
            "easydict                         1.11\n",
            "ecos                             2.0.12\n",
            "editdistance                     0.6.2\n",
            "eerepr                           0.0.4\n",
            "en-core-web-sm                   3.6.0\n",
            "entrypoints                      0.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.6.0\n",
            "etuples                          0.3.9\n",
            "exceptiongroup                   1.2.0\n",
            "faiss-cpu                        1.7.4\n",
            "fastai                           2.7.13\n",
            "fastcore                         1.5.29\n",
            "fastdownload                     0.0.7\n",
            "fastjsonschema                   2.19.0\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.2\n",
            "filelock                         3.13.1\n",
            "fiona                            1.9.5\n",
            "firebase-admin                   5.3.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      23.5.26\n",
            "flax                             0.7.5\n",
            "folium                           0.14.0\n",
            "fonttools                        4.46.0\n",
            "frozendict                       2.3.10\n",
            "frozenlist                       1.4.1\n",
            "fsspec                           2023.6.0\n",
            "future                           0.18.3\n",
            "gast                             0.5.4\n",
            "gcsfs                            2023.6.0\n",
            "GDAL                             3.4.3\n",
            "gdown                            4.6.6\n",
            "geemap                           0.29.6\n",
            "gensim                           4.3.2\n",
            "geocoder                         1.38.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.13.2\n",
            "geopy                            2.3.0\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-ai-generativelanguage     0.4.0\n",
            "google-api-core                  2.11.1\n",
            "google-api-python-client         2.84.0\n",
            "google-auth                      2.17.3\n",
            "google-auth-httplib2             0.1.1\n",
            "google-auth-oauthlib             1.2.0\n",
            "google-cloud-aiplatform          1.38.1\n",
            "google-cloud-bigquery            3.12.0\n",
            "google-cloud-bigquery-connection 1.12.1\n",
            "google-cloud-bigquery-storage    2.24.0\n",
            "google-cloud-core                2.3.3\n",
            "google-cloud-datastore           2.15.2\n",
            "google-cloud-firestore           2.11.1\n",
            "google-cloud-functions           1.13.3\n",
            "google-cloud-iam                 2.13.0\n",
            "google-cloud-language            2.9.1\n",
            "google-cloud-resource-manager    1.11.0\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.11.3\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-generativeai              0.3.1\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.7.0\n",
            "googleapis-common-protos         1.62.0\n",
            "googledrivedownloader            0.4\n",
            "graphviz                         0.20.1\n",
            "greenlet                         3.0.2\n",
            "grpc-google-iam-v1               0.13.0\n",
            "grpcio                           1.60.0\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          3.4.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h5netcdf                         1.3.0\n",
            "h5py                             3.9.0\n",
            "holidays                         0.38\n",
            "holoviews                        1.17.1\n",
            "html5lib                         1.1\n",
            "httpimport                       1.3.1\n",
            "httplib2                         0.22.0\n",
            "huggingface-hub                  0.19.4\n",
            "humanize                         4.7.0\n",
            "hyperopt                         0.2.7\n",
            "ibis-framework                   6.2.0\n",
            "idna                             3.6\n",
            "imageio                          2.31.6\n",
            "imageio-ffmpeg                   0.4.9\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.10.1\n",
            "imgaug                           0.4.0\n",
            "importlib-metadata               7.0.0\n",
            "importlib-resources              6.1.1\n",
            "imutils                          0.5.4\n",
            "inflect                          7.0.0\n",
            "iniconfig                        2.0.0\n",
            "install                          1.3.5\n",
            "intel-openmp                     2023.2.3\n",
            "ipyevents                        2.0.2\n",
            "ipyfilechooser                   0.6.0\n",
            "ipykernel                        5.5.6\n",
            "ipyleaflet                       0.18.1\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.5.0\n",
            "ipytree                          0.2.2\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.1.2\n",
            "jax                              0.4.23\n",
            "jaxlib                           0.4.23+cuda12.cudnn89\n",
            "jeepney                          0.7.1\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.2\n",
            "joblib                           1.3.2\n",
            "jsonpatch                        1.33\n",
            "jsonpickle                       3.0.2\n",
            "jsonpointer                      2.4\n",
            "jsonschema                       4.19.2\n",
            "jsonschema-specifications        2023.11.2\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.5.1\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab_pygments              0.3.0\n",
            "jupyterlab-widgets               3.0.9\n",
            "kaggle                           1.5.16\n",
            "kagglehub                        0.1.4\n",
            "keras                            2.15.0\n",
            "keyring                          23.5.0\n",
            "kiwisolver                       1.4.5\n",
            "langchain                        0.0.309\n",
            "langcodes                        3.3.0\n",
            "langsmith                        0.0.75\n",
            "launchpadlib                     1.10.16\n",
            "lazr.restfulclient               0.14.4\n",
            "lazr.uri                         1.0.6\n",
            "lazy_loader                      0.3\n",
            "libclang                         16.0.6\n",
            "librosa                          0.10.1\n",
            "lida                             0.0.10\n",
            "lightgbm                         4.1.0\n",
            "linkify-it-py                    2.0.2\n",
            "llmx                             0.0.15a0\n",
            "llvmlite                         0.41.1\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "lxml                             4.9.3\n",
            "malloy                           2023.1067\n",
            "Markdown                         3.5.1\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.3\n",
            "marshmallow                      3.20.1\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.6\n",
            "matplotlib-venn                  0.11.9\n",
            "mdit-py-plugins                  0.4.0\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.9.3\n",
            "mkl                              2023.2.0\n",
            "ml-dtypes                        0.2.0\n",
            "mlxtend                          0.22.0\n",
            "more-itertools                   10.1.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.7\n",
            "multidict                        6.0.4\n",
            "multipledispatch                 1.0.0\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.10\n",
            "music21                          9.1.0\n",
            "mypy-extensions                  1.0.0\n",
            "natsort                          8.4.0\n",
            "nbclassic                        1.0.0\n",
            "nbclient                         0.9.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.9.2\n",
            "nest-asyncio                     1.5.8\n",
            "networkx                         3.2.1\n",
            "nibabel                          4.0.2\n",
            "nltk                             3.8.1\n",
            "notebook                         6.5.5\n",
            "notebook_shim                    0.2.3\n",
            "numba                            0.58.1\n",
            "numexpr                          2.8.8\n",
            "numpy                            1.23.5\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "opencv-contrib-python            4.8.0.76\n",
            "opencv-python                    4.8.0.76\n",
            "opencv-python-headless           4.8.1.78\n",
            "openpyxl                         3.1.2\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.1.7\n",
            "orbax-checkpoint                 0.4.4\n",
            "osqp                             0.6.2.post8\n",
            "packaging                        23.2\n",
            "pandas                           1.5.3\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.19.2\n",
            "pandas-stubs                     1.5.3.230304\n",
            "pandocfilters                    1.5.0\n",
            "panel                            1.3.4\n",
            "param                            2.0.1\n",
            "parso                            0.8.3\n",
            "parsy                            2.1\n",
            "partd                            1.4.1\n",
            "pathlib                          1.0.1\n",
            "pathy                            0.10.3\n",
            "patsy                            0.5.4\n",
            "peewee                           3.17.0\n",
            "pexpect                          4.9.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           9.4.0\n",
            "pip                              23.1.2\n",
            "pip-tools                        6.13.0\n",
            "platformdirs                     4.1.0\n",
            "plotly                           5.15.0\n",
            "plotnine                         0.12.4\n",
            "pluggy                           1.3.0\n",
            "polars                           0.17.3\n",
            "pooch                            1.8.0\n",
            "portpicker                       1.5.2\n",
            "prefetch-generator               1.0.3\n",
            "preshed                          3.0.9\n",
            "prettytable                      3.9.0\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus-client                0.19.0\n",
            "promise                          2.3\n",
            "prompt-toolkit                   3.0.43\n",
            "prophet                          1.1.5\n",
            "proto-plus                       1.23.0\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.9\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          10.0.1\n",
            "pyasn1                           0.5.1\n",
            "pyasn1-modules                   0.3.0\n",
            "pycocotools                      2.0.7\n",
            "pycparser                        2.21\n",
            "pyct                             0.5.0\n",
            "pydantic                         1.10.13\n",
            "pydata-google-auth               1.8.2\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "PyDrive2                         1.6.3\n",
            "pyerfa                           2.0.1.1\n",
            "pygame                           2.5.2\n",
            "Pygments                         2.16.1\n",
            "PyGObject                        3.42.1\n",
            "PyJWT                            2.3.0\n",
            "pymc                             5.7.2\n",
            "pymystem3                        0.2.0\n",
            "PyOpenGL                         3.1.7\n",
            "pyOpenSSL                        23.3.0\n",
            "pyparsing                        3.1.1\n",
            "pypdf                            3.15.1\n",
            "pyperclip                        1.8.2\n",
            "pyproj                           3.6.1\n",
            "pyproject_hooks                  1.0.0\n",
            "pyshp                            2.3.1\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.14.2\n",
            "pytest                           7.4.3\n",
            "python-apt                       0.0.0\n",
            "python-box                       7.1.1\n",
            "python-dateutil                  2.8.2\n",
            "python-dotenv                    0.21.1\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.1\n",
            "python-utils                     3.8.1\n",
            "pytz                             2023.3.post1\n",
            "pyviz_comms                      3.0.0\n",
            "PyWavelets                       1.5.0\n",
            "PyYAML                           6.0.1\n",
            "pyzmq                            23.2.1\n",
            "qdldl                            0.1.7.post0\n",
            "qudida                           0.0.4\n",
            "ratelim                          0.1.6\n",
            "referencing                      0.32.0\n",
            "regex                            2023.6.3\n",
            "requests                         2.31.0\n",
            "requests-oauthlib                1.3.1\n",
            "requirements-parser              0.5.0\n",
            "rich                             13.7.0\n",
            "rpds-py                          0.15.2\n",
            "rpy2                             3.4.2\n",
            "rsa                              4.9\n",
            "safetensors                      0.4.1\n",
            "scikit-image                     0.19.3\n",
            "scikit-learn                     1.2.2\n",
            "scipy                            1.11.4\n",
            "scooby                           0.9.2\n",
            "scs                              3.2.4.post1\n",
            "seaborn                          0.12.2\n",
            "SecretStorage                    3.3.1\n",
            "Send2Trash                       1.8.2\n",
            "setuptools                       67.7.2\n",
            "shapely                          2.0.2\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       6.4.0\n",
            "sniffio                          1.3.0\n",
            "snowballstemmer                  2.2.0\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.5\n",
            "soxr                             0.3.7\n",
            "spacy                            3.6.1\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.5\n",
            "Sphinx                           5.0.2\n",
            "sphinxcontrib-applehelp          1.0.7\n",
            "sphinxcontrib-devhelp            1.0.5\n",
            "sphinxcontrib-htmlhelp           2.0.4\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             1.0.6\n",
            "sphinxcontrib-serializinghtml    1.1.9\n",
            "SQLAlchemy                       2.0.23\n",
            "sqlglot                          17.16.2\n",
            "sqlparse                         0.4.4\n",
            "srsly                            2.4.8\n",
            "stanio                           0.3.0\n",
            "statsmodels                      0.14.1\n",
            "sympy                            1.12\n",
            "tables                           3.8.0\n",
            "tabulate                         0.9.0\n",
            "tbb                              2021.11.0\n",
            "tblib                            3.0.0\n",
            "tenacity                         8.2.3\n",
            "tensorboard                      2.15.1\n",
            "tensorboard-data-server          0.7.2\n",
            "tensorflow                       2.15.0\n",
            "tensorflow-datasets              4.9.4\n",
            "tensorflow-estimator             2.15.0\n",
            "tensorflow-gcs-config            2.15.0\n",
            "tensorflow-hub                   0.15.0\n",
            "tensorflow-io-gcs-filesystem     0.34.0\n",
            "tensorflow-metadata              1.14.0\n",
            "tensorflow-probability           0.22.0\n",
            "tensorstore                      0.1.45\n",
            "termcolor                        2.4.0\n",
            "terminado                        0.18.0\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.1.12\n",
            "threadpoolctl                    3.2.0\n",
            "tifffile                         2023.12.9\n",
            "tinycss2                         1.2.1\n",
            "tokenizers                       0.15.0\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "toolz                            0.12.0\n",
            "torch                            2.1.0+cu121\n",
            "torchaudio                       2.1.0+cu121\n",
            "torchdata                        0.7.0\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.16.0\n",
            "torchvision                      0.16.0+cu121\n",
            "tornado                          6.3.2\n",
            "tqdm                             4.66.1\n",
            "traitlets                        5.7.1\n",
            "traittypes                       0.2.1\n",
            "transformers                     4.35.2\n",
            "triton                           2.1.0\n",
            "tweepy                           4.14.0\n",
            "typer                            0.9.0\n",
            "types-pytz                       2023.3.1.1\n",
            "types-setuptools                 69.0.0.0\n",
            "typing_extensions                4.5.0\n",
            "typing-inspect                   0.9.0\n",
            "tzlocal                          5.2\n",
            "uc-micro-py                      1.0.2\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          2.0.7\n",
            "vega-datasets                    0.9.0\n",
            "wadllib                          1.3.6\n",
            "wasabi                           1.1.2\n",
            "wcwidth                          0.2.12\n",
            "webcolors                        1.13\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.7.0\n",
            "Werkzeug                         3.0.1\n",
            "wheel                            0.42.0\n",
            "widgetsnbextension               3.6.6\n",
            "wordcloud                        1.9.3\n",
            "wrapt                            1.14.1\n",
            "xarray                           2023.7.0\n",
            "xarray-einstats                  0.6.0\n",
            "xgboost                          2.0.2\n",
            "xlrd                             2.0.1\n",
            "xxhash                           3.4.1\n",
            "xyzservices                      2023.10.1\n",
            "yarl                             1.9.4\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.33\n",
            "zict                             3.0.0\n",
            "zipp                             3.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "582419ab-471e-4bdf-8b6a-a49c57f2a882",
      "metadata": {
        "tags": [],
        "id": "582419ab-471e-4bdf-8b6a-a49c57f2a882"
      },
      "source": [
        "## Fetching and Processing the Sample Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8063d9f-0c5d-4e33-9e01-dce73b45c2ab",
      "metadata": {
        "id": "e8063d9f-0c5d-4e33-9e01-dce73b45c2ab"
      },
      "source": [
        "Next, fetch the sample data for this example. This section will download the publicly available Amazon Letters to Shareholders, that are provided yearly as a \"Year in Review\" of Amazon's business.\n",
        "\n",
        "This will download the pdfs locally and store them in a `data` directory local to this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ffb4b3c4-4eea-4a4e-87cc-2401830ef953",
      "metadata": {
        "tags": [],
        "id": "ffb4b3c4-4eea-4a4e-87cc-2401830ef953"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ./data\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "urls = [\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
        "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf'\n",
        "]\n",
        "\n",
        "filenames = [\n",
        "    'AMZN-2022-Shareholder-Letter.pdf',\n",
        "    'AMZN-2021-Shareholder-Letter.pdf',\n",
        "    'AMZN-2020-Shareholder-Letter.pdf',\n",
        "    'AMZN-2019-Shareholder-Letter.pdf'\n",
        "]\n",
        "\n",
        "metadata = [\n",
        "    dict(year=2022, source=filenames[0]),\n",
        "    dict(year=2021, source=filenames[1]),\n",
        "    dict(year=2020, source=filenames[2]),\n",
        "    dict(year=2019, source=filenames[3])]\n",
        "\n",
        "data_root = \"./data/\"\n",
        "\n",
        "for idx, url in enumerate(urls):\n",
        "    file_path = data_root + filenames[idx]\n",
        "    urlretrieve(url, file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ad1137c-ecfa-4d54-ba0e-843de52c1c5b",
      "metadata": {
        "id": "9ad1137c-ecfa-4d54-ba0e-843de52c1c5b"
      },
      "source": [
        "As a part of Amazon's peculiar culture, the CEO always attaches the original 1997 Letter to Shareholders to the current letter. To reduce the amount of processing necessary, reduce bias towards that year, and improve output, you will use PyPDF to remove those pages from each file and re-save it over the original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4d1ff002-8c3e-4c19-92b4-d333b9919fbf",
      "metadata": {
        "tags": [],
        "id": "4d1ff002-8c3e-4c19-92b4-d333b9919fbf"
      },
      "outputs": [],
      "source": [
        "from pypdf import PdfReader, PdfWriter\n",
        "import glob\n",
        "\n",
        "local_pdfs = glob.glob(data_root + '*.pdf')\n",
        "\n",
        "for local_pdf in local_pdfs:\n",
        "    pdf_reader = PdfReader(local_pdf)\n",
        "    pdf_writer = PdfWriter()\n",
        "    for pagenum in range(len(pdf_reader.pages)-3):\n",
        "        page = pdf_reader.pages[pagenum]\n",
        "        pdf_writer.add_page(page)\n",
        "\n",
        "    with open(local_pdf, 'wb') as new_file:\n",
        "        new_file.seek(0)\n",
        "        pdf_writer.write(new_file)\n",
        "        new_file.truncate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ed7c20b-45c3-4de5-8352-bb8991074a4d",
      "metadata": {
        "id": "0ed7c20b-45c3-4de5-8352-bb8991074a4d"
      },
      "source": [
        "Now that you have clean PDFs to work with, they need to be broken down into manageable pieces so you can provide the most relevant sections to the LLM as part of your RAG workflow. Here, you will iterate over all the documents and break them down into 512 character chunks with an overlap of 100 characters.\n",
        "\n",
        "The `chunk_size` dictates the size of the documents that will be embedded and stored in the vector database.\n",
        "\n",
        "The `chunk_overlap` dictates the amount of text that is used from a previous chunk when building the next one. This allows you to maintain some of the context between chunks.\n",
        "\n",
        "The `RecursiveCharacterTextSplitter` attempts to split up text recursively using delimeters of `[\"\\n\\n\", \"\\n\", \" \", \"\"]` until achieving the desired chunk size. This attempts to keep paragraphs/sentences/words together to allow for better semantic analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dd66b0d4-dc7e-4283-a7f7-e1b793f0dc4a",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd66b0d4-dc7e-4283-a7f7-e1b793f0dc4a",
        "outputId": "5f4cab78-d86d-4ded-ec4a-e2139bfde820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of Document Pages 25\n",
            "# of Document Chunks: 299\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
        "\n",
        "documents = []\n",
        "\n",
        "for idx, file in enumerate(filenames):\n",
        "    loader = PyPDFLoader(data_root + file)\n",
        "    document = loader.load()\n",
        "    for document_fragment in document:\n",
        "        document_fragment.metadata = metadata[idx]\n",
        "\n",
        "    documents += document\n",
        "\n",
        "# - in our testing Character split works better with this PDF data set\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 512,\n",
        "    chunk_overlap  = 100,\n",
        ")\n",
        "\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f'# of Document Pages {len(documents)}')\n",
        "print(f'# of Document Chunks: {len(docs)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e640ff1f-b6c5-48ae-86ab-a69b629f7c1b",
      "metadata": {
        "tags": [],
        "id": "e640ff1f-b6c5-48ae-86ab-a69b629f7c1b"
      },
      "source": [
        "## Deploy Model for Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b65f48b4-0155-46e4-9165-b8faf5d70096",
      "metadata": {
        "id": "b65f48b4-0155-46e4-9165-b8faf5d70096"
      },
      "source": [
        "In the following sections you will need to deploy a set of ML Models, one for Embeddings and a LLM for Language Generation. This example assumes you are working inside of SageMaker studio, so you can deploy them yourself or through SageMaker Jumpstart.\n",
        "\n",
        "For these examples, you will use `All MiniLM L6 v2` as the embedding model, and `LLaMa-2-7B-chat` as the LLM for language generation.\n",
        "\n",
        "__Note:__ If you choose other options, you may have to adjust the `transform_input` and `transform_output` functions in future sections for embedding and llm to match the models you've selected.\n",
        "\n",
        "Refer to the [SageMaker Jumpstart Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html) for details on how to deploy models via Jumpstart.\n",
        "\n",
        "If you already have an embedding endpoint deployed, you can skip the following cell, and modify the `embedding_model_endpoint_name` value to match your endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b8c44af9-fb91-4773-bc5f-c8d7459db772",
      "metadata": {
        "tags": [],
        "id": "b8c44af9-fb91-4773-bc5f-c8d7459db772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "61a78fc9-9db1-4515-ede7-464171db2173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sagemaker\n",
            "  Downloading sagemaker-2.202.1-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs<24,>=23.1.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (23.1.0)\n",
            "Collecting boto3<2.0,>=1.33.3 (from sagemaker)\n",
            "  Downloading boto3-1.34.7-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle==2.2.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (2.2.1)\n",
            "Requirement already satisfied: google-pasta in /usr/local/lib/python3.10/dist-packages (from sagemaker) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (1.23.5)\n",
            "Requirement already satisfied: protobuf<5.0,>=3.12 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (3.20.3)\n",
            "Collecting smdebug-rulesconfig==1.0.1 (from sagemaker)\n",
            "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
            "Collecting importlib-metadata<7.0,>=1.4.0 (from sagemaker)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (23.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from sagemaker) (1.5.3)\n",
            "Collecting pathos (from sagemaker)\n",
            "  Downloading pathos-0.3.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting schema (from sagemaker)\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: PyYAML~=6.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker) (6.0.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from sagemaker) (4.19.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from sagemaker) (4.1.0)\n",
            "Collecting tblib<3,>=1.7.0 (from sagemaker)\n",
            "  Downloading tblib-2.0.0-py3-none-any.whl (11 kB)\n",
            "Collecting urllib3<1.27 (from sagemaker)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn==0.22.0 (from sagemaker)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi==0.95.2 (from sagemaker)\n",
            "  Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from sagemaker) (2.31.0)\n",
            "Collecting docker (from sagemaker)\n",
            "  Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sagemaker) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from sagemaker) (5.9.5)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.95.2->sagemaker) (1.10.13)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi==0.95.2->sagemaker)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn==0.22.0->sagemaker) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn==0.22.0->sagemaker)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.35.0,>=1.34.7 (from boto3<2.0,>=1.33.3->sagemaker)\n",
            "  Downloading botocore-1.34.7-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.33.3->sagemaker)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0,>=1.33.3->sagemaker)\n",
            "  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->sagemaker) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->sagemaker) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->sagemaker) (2023.11.17)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from google-pasta->sagemaker) (1.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->sagemaker) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->sagemaker) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->sagemaker) (2023.3.post1)\n",
            "Collecting ppft>=1.7.6.7 (from pathos->sagemaker)\n",
            "  Downloading ppft-1.7.6.7-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill>=0.3.7 (from pathos->sagemaker)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pox>=0.3.3 (from pathos->sagemaker)\n",
            "  Downloading pox-0.3.3-py3-none-any.whl (29 kB)\n",
            "Collecting multiprocess>=0.70.15 (from pathos->sagemaker)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema->sagemaker) (21.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi==0.95.2->sagemaker) (4.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi==0.95.2->sagemaker) (3.7.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi==0.95.2->sagemaker) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi==0.95.2->sagemaker) (1.2.0)\n",
            "Installing collected packages: urllib3, tblib, smdebug-rulesconfig, schema, ppft, pox, jmespath, importlib-metadata, h11, dill, uvicorn, starlette, multiprocess, botocore, s3transfer, pathos, fastapi, docker, boto3, sagemaker\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: tblib\n",
            "    Found existing installation: tblib 3.0.0\n",
            "    Uninstalling tblib-3.0.0:\n",
            "      Successfully uninstalled tblib-3.0.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 7.0.0\n",
            "    Uninstalling importlib-metadata-7.0.0:\n",
            "      Successfully uninstalled importlib-metadata-7.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed boto3-1.34.7 botocore-1.34.7 dill-0.3.7 docker-7.0.0 fastapi-0.95.2 h11-0.14.0 importlib-metadata-6.11.0 jmespath-1.0.1 multiprocess-0.70.15 pathos-0.3.1 pox-0.3.3 ppft-1.7.6.7 s3transfer-0.10.0 sagemaker-2.202.1 schema-0.7.5 smdebug-rulesconfig-1.0.1 starlette-0.27.0 tblib-2.0.0 urllib3-1.26.18 uvicorn-0.22.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.34.7)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.7 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.34.7)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.7->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.7->boto3) (1.26.18)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.7->boto3) (1.16.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (1.26.18)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.18\n",
            "    Uninstalling urllib3-1.26.18:\n",
            "      Successfully uninstalled urllib3-1.26.18\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "botocore 1.34.7 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.1.0 which is incompatible.\n",
            "sagemaker 2.202.1 requires urllib3<1.27, but you have urllib3 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed urllib3-2.1.0\n",
            "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
            "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
            "---------!"
          ]
        }
      ],
      "source": [
        "# https://docs.aws.amazon.com/sagemaker/latest/dg/gs-set-up.html\n",
        "# https://stackoverflow.com/questions/68607118/aws-sagemaker-iam-permission-to-call-get-role\n",
        "\n",
        "!pip install sagemaker\n",
        "!pip install boto3\n",
        "!pip install --upgrade urllib3\n",
        "\n",
        "import boto3\n",
        "import sagemaker\n",
        "from sagemaker.jumpstart.model import JumpStartModel\n",
        "\n",
        "iam_client = boto3.client(\"iam\")\n",
        "\n",
        "role = iam_client.get_role(\n",
        "    RoleName=os.getenv(\"ROLENAME\")\n",
        ")\n",
        "\n",
        "ROLE_ARN = role['Role']['Arn']\n",
        "\n",
        "#print()\n",
        "#print(f\"ROLE_ARN: ('{ROLE_ARN}')\")\n",
        "#print()\n",
        "\n",
        "#role = iam_client.get_role(RoleName=‘{IAM_ROLE_WITH_SAGEMAKER_PERMISSIONS}’)[‘Role’][‘Arn’]\n",
        "\n",
        "# # Delete the SageMaker endpoint\n",
        "# predictor.delete_model()\n",
        "# predictor.delete_endpoint()\n",
        "\n",
        "#print(region)\n",
        "\n",
        "#mistral- TBD\n",
        "#model = JumpStartModel(model_id=\"huggingface-llm-mistral-7b-instruct\")\n",
        "\n",
        "# Use the IAM role ARN for the `executionRoleArn` parameter.\n",
        "\n",
        "embedding_model_id, embedding_model_version = \"huggingface-textembedding-all-MiniLM-L6-v2\", \"1.0.0\"\n",
        "model = JumpStartModel(model_id=embedding_model_id, model_version=embedding_model_version, role=ROLE_ARN)#model = JumpStartModel(model_id=embedding_model_id, model_version=embedding_model_version)\n",
        "\n",
        "#JumpStartM\n",
        "\n",
        "embedding_predictor = model.deploy()\n",
        "\n",
        "\n",
        "### DELETE\n",
        "\n",
        "#aws_region = 'us-west-2'\n",
        "#import boto3\n",
        "#sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
        "#embedding_model_endpoint_name = embedding_predictor.endpoint_name\n",
        "#sagemaker_client.delete_endpoint(EndpointName=embedding_model_endpoint_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59583752-0a04-4fda-a3fa-3d30be3c4df5",
      "metadata": {
        "id": "59583752-0a04-4fda-a3fa-3d30be3c4df5"
      },
      "source": [
        "__Note: running the following cell will deploy a SageMaker endpoint. You will need to delete the endpoint to stop charges from accumulating. See the clean up step at the end of this notebook.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3e75dcdf-141a-4e2a-8e1b-1b1e039bb907",
      "metadata": {
        "tags": [],
        "id": "3e75dcdf-141a-4e2a-8e1b-1b1e039bb907"
      },
      "outputs": [],
      "source": [
        "#this is the model endpoint NAME, not the ARN\n",
        "embedding_model_endpoint_name = embedding_predictor.endpoint_name\n",
        "\n",
        "#embedding_model_endpoint_name_huggingface = embedding_predictor.endpoint_name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c84cacf-fffe-4500-ace2-bef19b7694e3",
      "metadata": {
        "id": "4c84cacf-fffe-4500-ace2-bef19b7694e3"
      },
      "source": [
        "To use your SageMaker model endpoints, you need to have a set of credentials. This section will assume them from your SageMaker Studio session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6cd7c3fa-0c39-4876-925f-ee3918e9bdb6",
      "metadata": {
        "tags": [],
        "id": "6cd7c3fa-0c39-4876-925f-ee3918e9bdb6"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "#aws_region = boto3.Session().region_name\n",
        "aws_region=region\n",
        "aws_region='us-east-1'\n",
        "#print(aws_region)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7696e9d-1d95-45fb-b575-76018d08e2ac",
      "metadata": {
        "id": "d7696e9d-1d95-45fb-b575-76018d08e2ac"
      },
      "source": [
        "## Creating and Populating the Vector Database"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e70bd413-4a32-4ab9-92d4-1bcfd6854933",
      "metadata": {
        "id": "e70bd413-4a32-4ab9-92d4-1bcfd6854933"
      },
      "source": [
        "Next you need to set up how to process the embeddings for the input documents.\n",
        "\n",
        "The provided CustomEmbeddingsContentHandler class has a set of functions, transform_input and transform_output, for porcessing data going into and out of the embedding model.\n",
        "\n",
        "With the content handler defined, you will then use the SageMakerEndpointEmbeddings class from LangChain to create an embeddings object that corresponds to your hosted embeddings model along with the appropriate content handler for processing its inputs/outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1a5aa464-6e62-4e4f-83aa-ea08545a93d4",
      "metadata": {
        "tags": [],
        "id": "1a5aa464-6e62-4e4f-83aa-ea08545a93d4"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List\n",
        "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
        "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\n",
        "import json\n",
        "\n",
        "\n",
        "class CustomEmbeddingsContentHandler(EmbeddingsContentHandler):\n",
        "    content_type = \"application/json\"\n",
        "    accepts = \"application/json\"\n",
        "\n",
        "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
        "        input_str = json.dumps({\"text_inputs\": inputs, **model_kwargs})\n",
        "        return input_str.encode(\"utf-8\")\n",
        "\n",
        "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
        "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
        "        return response_json[\"embedding\"]\n",
        "\n",
        "\n",
        "embeddings_content_handler = CustomEmbeddingsContentHandler()\n",
        "\n",
        "embeddings = SagemakerEndpointEmbeddings(\n",
        "    endpoint_name=embedding_model_endpoint_name,\n",
        "    region_name=aws_region,\n",
        "    content_handler=embeddings_content_handler,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "781c536f-4a3d-423a-8711-d3aed5f7a08c",
      "metadata": {
        "id": "781c536f-4a3d-423a-8711-d3aed5f7a08c"
      },
      "source": [
        "With our embeddings references ready, the next step is to actually process those document chunks into vectors and store them somewhere. This example uses a FAISS in-memory vector database, but there are many other options available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6feb6fba-9e9e-4880-860a-2c0c8f61c9df",
      "metadata": {
        "tags": [],
        "id": "6feb6fba-9e9e-4880-860a-2c0c8f61c9df"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "from langchain.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5a2b4c55-056e-4922-a7fa-4786b0d1dbcd",
      "metadata": {
        "tags": [],
        "id": "5a2b4c55-056e-4922-a7fa-4786b0d1dbcd"
      },
      "outputs": [],
      "source": [
        "db = FAISS.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b29a7597-abc0-4a14-8d6e-810893ff4a78",
      "metadata": {
        "tags": [],
        "id": "b29a7597-abc0-4a14-8d6e-810893ff4a78"
      },
      "source": [
        "## Running Vector Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bae5fdb-6881-4b9d-ba42-ed07f980183e",
      "metadata": {
        "id": "3bae5fdb-6881-4b9d-ba42-ed07f980183e"
      },
      "source": [
        "Now that you have a populated vector database, you can run queries against it to return relevant document chunks.\n",
        "\n",
        "Start with a simple query that corresponds to the source material."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b119c2c4-3dbe-41a0-87d2-1b85fcb0abb4",
      "metadata": {
        "tags": [],
        "id": "b119c2c4-3dbe-41a0-87d2-1b85fcb0abb4"
      },
      "outputs": [],
      "source": [
        "query = \"How has AWS evolved?\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8897cbb-7ce8-4b37-bb30-41d1c8ea887b",
      "metadata": {
        "tags": [],
        "id": "b8897cbb-7ce8-4b37-bb30-41d1c8ea887b"
      },
      "source": [
        "The results that come back from the `similarity_search_with_score` API are sorted by score from lowest to highest. The score value is represented by the [L-squared (or L2)](https://en.wikipedia.org/wiki/Lp_space) distance of each result. Lower scores are better, repesenting a shorter distance between vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b2a0069d-d864-49d4-90eb-c588fba0f9b0",
      "metadata": {
        "tags": [],
        "id": "b2a0069d-d864-49d4-90eb-c588fba0f9b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "860b7a92-e068-4bb4-c651-19c4bd5c9b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content: done innovating here,and this long-term investment should prove fruitful for both customers and AWS. AWS is still in the earlystages of its evolution, and has a chance for unusual growth in the next decade.\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.5685306191444397\n",
            "\n",
            "\n",
            "Content: customers, AWS continues to deliver new capabilities rapidly (over 3,300 new features and services launchedin 2022), and invest in long-term inventions that change what’s possible.\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.7789842486381531\n",
            "\n",
            "\n",
            "Content: We had a head start on potential competitors;and if anything, we wanted to accelerate our pace of innovation. We made the long-term decision tocontinue investing in AWS. Fifteen years later, AWS is now an $85B annual revenue run rate business, withstrong profitability, that has transformed how customers from start-ups to multinational companies to publicsector organizations manage their technology infrastructure. Amazon would be a different company ifwe’d slowed investment in AWS during that 2008-2009\n",
            "Metadata: {'year': 2022, 'source': 'AMZN-2022-Shareholder-Letter.pdf'}\n",
            "Score: 0.7893760204315186\n",
            "\n",
            "\n",
            "Content: back and determining what they wanted to change coming out of the pandemic. Many concludedthat they didn’t want to continue managing their technology infrastructure themselves, and made thedecision to accelerate their move to the cloud. This shift by so many companies (along with the economyrecovering) helped re-accelerate AWS’s revenue growth to 37% Y oY in 2021.\n",
            "Metadata: {'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
            "Score: 0.7898486852645874\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "results_with_scores = db.similarity_search_with_score(query)\n",
        "for doc, score in results_with_scores:\n",
        "    print(f\"Content: {doc.page_content}\\nMetadata: {doc.metadata}\\nScore: {score}\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ff8e58e5-baff-4d2f-b3d7-614016b13f74",
      "metadata": {
        "tags": [],
        "id": "ff8e58e5-baff-4d2f-b3d7-614016b13f74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "874c971b-da8e-434f-886d-09d0f9069411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content: back and determining what they wanted to change coming out of the pandemic. Many concludedthat they didn’t want to continue managing their technology infrastructure themselves, and made thedecision to accelerate their move to the cloud. This shift by so many companies (along with the economyrecovering) helped re-accelerate AWS’s revenue growth to 37% Y oY in 2021.\n",
            "Metadata: {'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
            "Score: 0.7898486852645874\n",
            "\n",
            "\n",
            "Content: customersmuch more functionality in AWS than they can find anywhere else (which is a significant differentiator), butalso allowed us to arrive at the much more game-changing offering that AWS is today.\n",
            "Metadata: {'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
            "Score: 0.8196681141853333\n",
            "\n",
            "\n",
            "Content: AWS : As we were defining AWS and working backwards on the services we thought customers wanted, we\n",
            "Metadata: {'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
            "Score: 0.8815345764160156\n",
            "\n",
            "\n",
            "Content: it’s been. Whatever role Amazon played in the world up to that point became further magnified as mostphysical venues shut down for long periods of time and people spent their days at home. This meant thathundreds of millions of people relied on Amazon for PPE, food, clothing, and various other items thathelped them navigate this unprecedented time. Businesses and governments also had to shift, practicallyovernight, from working with colleagues and technology on-premises to working remotely. AWS played\n",
            "Metadata: {'year': 2021, 'source': 'AMZN-2021-Shareholder-Letter.pdf'}\n",
            "Score: 0.9350287318229675\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "filter={\"year\": 2021}\n",
        "\n",
        "results_with_scores = db.similarity_search_with_score(query,\n",
        "  filter=filter)\n",
        "\n",
        "for doc, score in results_with_scores:\n",
        "    print(f\"Content: {doc.page_content}\\nMetadata: {doc.metadata}\\nScore: {score}\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fa9bd43-f485-4acd-bf4a-aa2661f3ad2b",
      "metadata": {
        "id": "3fa9bd43-f485-4acd-bf4a-aa2661f3ad2b"
      },
      "source": [
        "## Creating Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ad27408-6e86-4469-88d9-410c8784c6f9",
      "metadata": {
        "id": "1ad27408-6e86-4469-88d9-410c8784c6f9"
      },
      "source": [
        "You've gotten results from your vector database, but currently they are just chunks of the original documents and some of them might not even contain the information you want to provide as an answer to your original query.\n",
        "\n",
        "To generate the appropriate response, you will leverage a prompt template that takes the original question asked along with relevant context chunks from your vector database to generate a new response from your language generator model.\n",
        "\n",
        "LangChain provides functionality to allow for easier creation and population of prompt templates. The template below has specific markup for LLaMa-2-chat, but also has placeholder values for `{context}` and `{question}`, which you will provide to fill out the template."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "80de40d9-4525-4e6a-8af0-f4a567a8fc5f",
      "metadata": {
        "tags": [],
        "id": "80de40d9-4525-4e6a-8af0-f4a567a8fc5f"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "<s>[INST] <<SYS>>\n",
        "Use the context provided to answer the question at the end. If you dont know the answer just say that you don't know, don't try to make up an answer.\n",
        "<</SYS>>\n",
        "\n",
        "Context:\n",
        "----------------\n",
        "{context}\n",
        "----------------\n",
        "\n",
        "Question: {question} [/INST]\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template,\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14a7a714-e1bc-4c75-8316-c56a47a21353",
      "metadata": {
        "id": "14a7a714-e1bc-4c75-8316-c56a47a21353"
      },
      "source": [
        "## Preparing the LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "423e7a61-132a-4b1f-ba39-5b9e2d577141",
      "metadata": {
        "id": "423e7a61-132a-4b1f-ba39-5b9e2d577141"
      },
      "source": [
        "The next step is a process similar to the one you did earlier for the embedding model, but now for your LLM.\n",
        "\n",
        "In the QAContentHandler class, you will see `transform_input` and `transform_output` functions to manipulate the inputs and outputs of your LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "949f5a8a-581d-43a6-8c1d-2a7eb998dbf7",
      "metadata": {
        "tags": [],
        "id": "949f5a8a-581d-43a6-8c1d-2a7eb998dbf7"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "\n",
        "from langchain import PromptTemplate, SagemakerEndpoint\n",
        "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains import RetrievalQA\n",
        "import json\n",
        "\n",
        "\n",
        "class QAContentHandler(LLMContentHandler):\n",
        "    content_type = \"application/json\"\n",
        "    accepts = \"application/json\"\n",
        "\n",
        "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
        "        input_str = json.dumps(\n",
        "            {\"inputs\" : [\n",
        "                [\n",
        "                    {\n",
        "                        \"role\" : \"system\",\n",
        "                        \"content\" : \"\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\" : \"user\",\n",
        "                        \"content\" : prompt\n",
        "                    }\n",
        "                ]],\n",
        "                \"parameters\" : {**model_kwargs}\n",
        "            })\n",
        "        return input_str.encode('utf-8')\n",
        "\n",
        "    def transform_output(self, output: bytes) -> str:\n",
        "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
        "        return response_json[0][\"generation\"][\"content\"]\n",
        "        #return response_json[0]['generated_text'][\"content\"]\n",
        "\n",
        "\n",
        "\n",
        "qa_content_handler = QAContentHandler()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8065bc98-ddd4-4c2d-bb92-8572f7483c63",
      "metadata": {
        "id": "8065bc98-ddd4-4c2d-bb92-8572f7483c63"
      },
      "source": [
        "Now you will deploy a SageMaker endpoint for language generation LLM. Afterward you will create an object pointed to that endpoint and provide inference parameters to the endpoint and model.\n",
        "\n",
        "If you already have a LLM endpoint deployed, you can skip the following cell, and modify the `llm_model_endpoint_name` value to match your endpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8386fdd6-7aee-4cde-a601-521007b31c3c",
      "metadata": {
        "id": "8386fdd6-7aee-4cde-a601-521007b31c3c"
      },
      "source": [
        "iam_client = boto3.client(\"iam\")\n",
        "\n",
        "role = iam_client.get_role(\n",
        "    RoleName=os.getenv(\"ROLENAME\")\n",
        ")\n",
        "\n",
        "ROLE_ARN = role['Role']['Arn']__Note: running the following cell will deploy a SageMaker endpoint which takes a few minutes. You will need to delete the endpoint to stop charges from accumulating. See the clean up step at the end of this notebook.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "56f21bd6-2616-4c54-8e61-7f587861e94e",
      "metadata": {
        "tags": [],
        "id": "56f21bd6-2616-4c54-8e61-7f587861e94e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d489adc8-8879-49e6-edd7-92d658ef96c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------!"
          ]
        }
      ],
      "source": [
        "# added by frank morales december 13, 2023\n",
        "iam_client = boto3.client(\"iam\")\n",
        "\n",
        "role = iam_client.get_role(\n",
        "    RoleName=os.getenv(\"ROLENAME\")\n",
        ")\n",
        "\n",
        "ROLE_ARN = role['Role']['Arn']\n",
        "\n",
        "# https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-choose.html#jumpstart-foundation-models-choose-eula\n",
        "\n",
        "# modified by frank morales december 18, 2023.\n",
        "#(llm_model_id, llm_model_version,) = (\n",
        "#   \"meta-textgeneration-llama-2-7b\",\"2.1.8\",\n",
        "#)\n",
        "\n",
        "#(llm_model_id, llm_model_version,) = (\n",
        "#    \"meta-textgeneration-llama-2-7b\",\"*\",\n",
        "#)\n",
        "\n",
        "#original\n",
        "#llm_model_id, llm_model_version = \"meta-textgeneration-llama-2-7b-f\", \"*\"\n",
        "#llm_model = JumpStartModel(model_id=llm_model_id, model_version=llm_model_version)\n",
        "## error below\n",
        "\n",
        "#modified by frankmorales\n",
        "llm_model_id = 'meta-textgeneration-llama-2-7b'\n",
        "llm_model_version = '2.*'\n",
        "llm_model = JumpStartModel(model_id=llm_model_id, model_version=llm_model_version, role=ROLE_ARN, region='us-east-1')\n",
        "#modified by frankmorales\n",
        "llm_predictor = llm_model.deploy(accept_eula=True)\n",
        "\n",
        "#original\n",
        "#llm_predictor = llm_model.deploy()\n",
        "##error\n",
        "##ClientError: An error occurred (ValidationException) when calling the CreateModel operation: 1 validation error detected: Value 'arn:aws:iam::xxxxxxxxxxxx:user/xxx-xxxx' at 'executionRoleArn'\n",
        "##failed to satisfy constraint: Member must satisfy regular expression pattern: ^arn:aws[a-z\\-]*:iam::\\d{12}:role/?[a-zA-Z_0-9+=,.@\\-_/]+$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "b369788d-da6f-4f55-8b5f-10a82fe7e7ad",
      "metadata": {
        "tags": [],
        "id": "b369788d-da6f-4f55-8b5f-10a82fe7e7ad"
      },
      "outputs": [],
      "source": [
        "#this is the model endpoint NAME, not the ARN\n",
        "llm_model_endpoint_name = llm_predictor.endpoint_name\n",
        "#llm_model_endpoint_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0fe31a83-9892-4751-b6d9-30c69a3ef0f8",
      "metadata": {
        "tags": [],
        "id": "0fe31a83-9892-4751-b6d9-30c69a3ef0f8"
      },
      "outputs": [],
      "source": [
        "aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "region=os.getenv(\"region\")\n",
        "output=os.getenv(\"output\")\n",
        "\n",
        " #\"do_sample\": True,\n",
        " #           \"top_p\": 0.9,\n",
        " #           \"temperature\": 0.9,\n",
        " #           \"max_new_tokens\": 512,\n",
        " #           \"return_full_text\": False,\n",
        "\n",
        "llm = SagemakerEndpoint(\n",
        "        endpoint_name=llm_model_endpoint_name,\n",
        "        region_name=region,\n",
        "        model_kwargs={\"max_new_tokens\": 512, \"top_p\": 0.9, \"temperature\": 0.9},\n",
        "        endpoint_kwargs={\"CustomAttributes\": 'accept_eula=true'},\n",
        "        content_handler=qa_content_handler\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b0594e6-0c4d-4564-9da6-74e5b8b44b91",
      "metadata": {
        "id": "1b0594e6-0c4d-4564-9da6-74e5b8b44b91"
      },
      "source": [
        "You can invoke this LLM object directly to get a baseline response without any contextual information provided. You'll notice the answer to the question `How has AWS evolved?` is more about __what__ AWS has done rather than a more internal take on how AWS has evolved. This is likely due to the corpus of data that the LLM was trained on which contained a large amount of articles from the internet.\n",
        "\n",
        "Note that this is not a bad response by any stretch, but it might not be the response you're looking for.\n",
        "\n",
        "You'll see how context can evolve the reponse in a moment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ab06b378-162d-41c7-bac3-80fae801d1c0",
      "metadata": {
        "tags": [],
        "id": "ab06b378-162d-41c7-bac3-80fae801d1c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b9a86e4-e161-4fa4-de52-231377dae2ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generation': '\\nThe cloud is a fundamental shift in the way we build, deploy, and operate IT infrastructure. It’s not just a new technology or a new way of provisioning resources, it’s a new way of thinking about IT.\\nAWS has been around for over a decade now and has grown to become one of the most popular cloud providers in the world. In that time, AWS has evolved from a simple web hosting service to a full-fledged cloud platform with a wide range of services.\\nAWS has been a major player in the cloud computing space for years, but it’s only recently that the company has begun to truly dominate the market. In the past few years, AWS has launched a number of new services and features that have made it even more popular with businesses and developers.\\nOne of the most significant changes that AWS has made in recent years is its focus on artificial intelligence (AI). The company has made a number of investments in AI, including the acquisition of AI company DeepMind in 2014. AWS has also launched a number of new AI-powered services, such as Amazon Lex, which is used by businesses to build chatbots.\\nAWS has also been investing in other emerging technologies, such as blockchain and the Internet of Things (IoT). The company has launched a number of new services that are designed to help businesses and developers take advantage of these technologies, such as Amazon Managed Blockchain and Amazon IoT Greengrass.\\nOverall, AWS has come a long way since its early days as a simple web hosting service. The company has grown to become one of the most popular cloud providers in the world and is now a major player in the AI, blockchain, and IoT spaces.\\nWhat is AWS used for?\\nAWS is used for a variety of purposes, including web hosting, content delivery, and data storage. AWS is also used for a variety of other purposes, including machine learning, artificial intelligence, and the Internet of Things (IoT).\\nAWS is used for web hosting by a number of large and small businesses. AWS provides a variety of services that are designed to make it easy to host websites and applications. AWS also provides a number of services that are designed to make it easy to scale websites and applications.\\nAWS is used for content delivery by a number of large and small businesses. AWS provides a variety of services that are designed to make it easy to deliver content to users. AWS also provides a number of services that are designed to make it easy to scale content delivery.\\nAWS is used for data storage by a number of large and small businesses. AWS provides a variety of services that are designed to make it easy to store data. AWS also provides a number of services that are designed to make it easy to scale data storage.\\nAWS is used for machine learning by a number of large and small businesses. AWS provides a variety of services that are designed to make it easy to train and deploy machine learning models. AWS also provides a number of services that are designed to make it easy to scale machine learning.\\nAWS is used for artificial intelligence by a number of large and small businesses. AWS provides a variety of services that are designed to make it easy to build and deploy AI applications. AWS also provides a number of services that are designed to make it easy to scale AI applications.\\nAWS is used for the Internet of Things (IoT) by a number of large and small businesses. AWS provides a variety of services that are designed to make it easy to connect devices and applications. AWS also provides a number of services that are designed to make it easy to scale IoT applications.\\nWhat are the benefits of AWS?\\nAWS provides a number of benefits to businesses and developers, including:\\n-A wide range of services: AWS provides a wide range of services, including web hosting, content delivery, and data storage. AWS also provides a number of services that are designed to make it easy to build and deploy AI applications, machine learning models, and IoT applications.\\n-Scalability: AWS provides a number of services that are designed to make it easy to scale websites and applications. AWS also provides a number of services that are designed to make it easy to scale data storage and machine learning models.\\n-Security: AWS provides a number of services that are designed to make it easy to secure websites and applications. AWS also provides a number of services that are designed to make it easy to secure data storage and machine learning models.\\n-Cost savings: AWS provides a number of services that are designed to make it easy to save money on web hosting, content delivery, and data storage. AWS also provides a number of services that are designed to make it easy to save money on machine learning and AI applications.\\n-R'}]\n",
            "How has AWS evolved?\n",
            "\n",
            "==================================\n",
            "\n",
            "Answer: \n",
            "The cloud is a fundamental shift in the way we build, deploy, and operate IT infrastructure. It’s not just a new technology or a new way of provisioning resources, it’s a new way of thinking about IT.\n",
            "AWS has been around for over a decade now and has grown to become one of the most popular cloud providers in the world. In that time, AWS has evolved from a simple web hosting service to a full-fledged cloud platform with a wide range of services.\n",
            "AWS has been a major player in the cloud computing space for years, but it’s only recently that the company has begun to truly dominate the market. In the past few years, AWS has launched a number of new services and features that have made it even more popular with businesses and developers.\n",
            "One of the most significant changes that AWS has made in recent years is its focus on artificial intelligence (AI). The company has made a number of investments in AI, including the acquisition of AI company DeepMind in 2014. AWS has also launched a number of new AI-powered services, such as Amazon Lex, which is used by businesses to build chatbots.\n",
            "AWS has also been investing in other emerging technologies, such as blockchain and the Internet of Things (IoT). The company has launched a number of new services that are designed to help businesses and developers take advantage of these technologies, such as Amazon Managed Blockchain and Amazon IoT Greengrass.\n",
            "Overall, AWS has come a long way since its early days as a simple web hosting service. The company has grown to become one of the most popular cloud providers in the world and is now a major player in the AI, blockchain, and IoT spaces.\n",
            "What is AWS used for?\n",
            "AWS is used for a variety of purposes, including web hosting, content delivery, and data storage. AWS is also used for a variety of other purposes, including machine learning, artificial intelligence, and the Internet of Things (IoT).\n",
            "AWS is used for web hosting by a number of large and small businesses. AWS provides a variety of services that are designed to make it easy to host websites and applications. AWS also provides a number of services that are designed to make it easy to scale websites and applications.\n",
            "AWS is used for content delivery by a number of large and small businesses. AWS provides a variety of services that are designed to make it easy to deliver content to users. AWS also provides a number of services that are designed to make it easy to scale content delivery.\n",
            "AWS is used for data storage by a number of large and small businesses. AWS provides a variety of services that are designed to make it easy to store data. AWS also provides a number of services that are designed to make it easy to scale data storage.\n",
            "AWS is used for machine learning by a number of large and small businesses. AWS provides a variety of services that are designed to make it easy to train and deploy machine learning models. AWS also provides a number of services that are designed to make it easy to scale machine learning.\n",
            "AWS is used for artificial intelligence by a number of large and small businesses. AWS provides a variety of services that are designed to make it easy to build and deploy AI applications. AWS also provides a number of services that are designed to make it easy to scale AI applications.\n",
            "AWS is used for the Internet of Things (IoT) by a number of large and small businesses. AWS provides a variety of services that are designed to make it easy to connect devices and applications. AWS also provides a number of services that are designed to make it easy to scale IoT applications.\n",
            "What are the benefits of AWS?\n",
            "AWS provides a number of benefits to businesses and developers, including:\n",
            "-A wide range of services: AWS provides a wide range of services, including web hosting, content delivery, and data storage. AWS also provides a number of services that are designed to make it easy to build and deploy AI applications, machine learning models, and IoT applications.\n",
            "-Scalability: AWS provides a number of services that are designed to make it easy to scale websites and applications. AWS also provides a number of services that are designed to make it easy to scale data storage and machine learning models.\n",
            "-Security: AWS provides a number of services that are designed to make it easy to secure websites and applications. AWS also provides a number of services that are designed to make it easy to secure data storage and machine learning models.\n",
            "-Cost savings: AWS provides a number of services that are designed to make it easy to save money on web hosting, content delivery, and data storage. AWS also provides a number of services that are designed to make it easy to save money on machine learning and AI applications.\n",
            "-R\n",
            "\n",
            "==================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# added by frank morales dec 18, 2023\n",
        "# https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/jumpstart-foundation-models/llama-2-text-completion.ipynb\n",
        "\n",
        "#original by the book\n",
        "query = \"How has AWS evolved?\"\n",
        "#llm.predict(query)\n",
        "# have this error\n",
        "#ValueError: Error raised by inference endpoint: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (424) from primary with message \"{\n",
        "#  \"code\":424,\n",
        "#  \"message\":\"prediction failure\",\n",
        "#  \"error\":\"can only concatenate str (not \\\"list\\\") to str\"\n",
        "#}\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/meta-textgeneration-llama-2-7b-2023-12-18-08-21-44-646 in account  xxxxxxxxxxxx for more information.\n",
        "\n",
        "#workaround by frank morales\n",
        "payload = {\n",
        "    \"inputs\": \"%s\"%query,\n",
        "    \"parameters\": {\n",
        "        \"max_new_tokens\": 1024,\n",
        "        \"top_p\": 0.9,\n",
        "        \"temperature\": 0.6,\n",
        "        \"return_full_text\": False,\n",
        "    },\n",
        "}\n",
        "\n",
        "response = llm_predictor.predict(payload, custom_attributes='accept_eula=true')\n",
        "print(response)\n",
        "def print_response(payload, response):\n",
        "    print(payload[\"inputs\"])\n",
        "    #print(response)\n",
        "    # [{'generated_text':\n",
        "    print(\"\\n==================================\\n\")\n",
        "    #llm_model_version = '*' and '3.0.0'\n",
        "    #print(f\"Answer: {response[0]['generated_text']}\")\n",
        "\n",
        "    # llm_model_version = '2.*'\n",
        "    print(f\"Answer: {response[0]['generation']}\")\n",
        "\n",
        "\n",
        "    print(\"\\n==================================\\n\")\n",
        "\n",
        "print_response(payload, response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a43ea03c-83fb-4ef4-a4cb-cc6d3b26c2c3",
      "metadata": {
        "id": "a43ea03c-83fb-4ef4-a4cb-cc6d3b26c2c3"
      },
      "source": [
        "With the LLM endpoint object created, you are ready to create your first chain!\n",
        "\n",
        "This chain is a simple example using LangChain's RetrievalQA chain, which will:\n",
        "- take a query as input\n",
        "- generate query embeddings\n",
        "- query the vector database for relevant document chunks based on the query embedding\n",
        "- inject the context and original query into the prompt template\n",
        "- invoke the LLM with the completed prompt\n",
        "- return the LLM result\n",
        "\n",
        "The [`stuff` chain type](https://python.langchain.com/docs/modules/chains/document/stuff) simply takes the context documents and inserts them into the prompt.\n",
        "\n",
        "By setting `return_source_documents` to `True`, the LLM responses will also contain the document chunks from the vector database, to illustrate where the context came from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "6565df76-1c3f-4d5a-a78d-928766d6586b",
      "metadata": {
        "tags": [],
        "id": "6565df76-1c3f-4d5a-a78d-928766d6586b"
      },
      "outputs": [],
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    chain_type='stuff',\n",
        "    retriever=db.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": PROMPT}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d78919b-9019-4a06-95b2-c209fbdce562",
      "metadata": {
        "tags": [],
        "id": "8d78919b-9019-4a06-95b2-c209fbdce562"
      },
      "source": [
        "Now that your chain is set up, you can supply queries to it and generate responses based on your source documents.\n",
        "\n",
        "A few examples have been provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "473c77f3-a42f-407f-9231-07b2bb71fc76",
      "metadata": {
        "tags": [],
        "id": "473c77f3-a42f-407f-9231-07b2bb71fc76"
      },
      "outputs": [],
      "source": [
        "query = \"How has AWS evolved?\"\n",
        "result = qa_chain({\"query\": query})\n",
        "print(f'Query: {result[\"query\"]}\\n')\n",
        "print(f'Result: {result[\"result\"]}\\n')\n",
        "print(f'Context Documents: ')\n",
        "for srcdoc in result[\"source_documents\"]:\n",
        "      print(f'{srcdoc}\\n')\n",
        "\n",
        "### error\n",
        "#ModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (424) from primary with message \"{\n",
        "#  \"code\":424,\n",
        "#  \"message\":\"prediction failure\",\n",
        "#  \"error\":\"can only concatenate str (not \\\"list\\\") to str\"\n",
        "#}\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/meta-textgeneration-llama-2-7b-2023-12-18-21-47-42-330\n",
        "# in account xxxxxxxxxxxx for more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8ba6252-103e-4d12-936f-4ce91f139aed",
      "metadata": {
        "tags": [],
        "id": "b8ba6252-103e-4d12-936f-4ce91f139aed"
      },
      "outputs": [],
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    chain_type='stuff',\n",
        "    retriever=db.as_retriever(\n",
        "        search_type=\"mmr\", # Maximum Marginal Relevance (MMR)\n",
        "        search_kwargs={\"k\": 3, \"lambda_mult\": 0.1}\n",
        "    ),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": PROMPT}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf5d2e45-eb62-4790-81c1-ece18f4b7151",
      "metadata": {
        "tags": [],
        "id": "bf5d2e45-eb62-4790-81c1-ece18f4b7151"
      },
      "source": [
        "Now that your chain is set up, you can supply queries to it and generate responses based on your source documents.\n",
        "\n",
        "A few examples have been provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4816efb-1d74-433b-adaa-61ed50caff04",
      "metadata": {
        "tags": [],
        "id": "f4816efb-1d74-433b-adaa-61ed50caff04"
      },
      "outputs": [],
      "source": [
        "query = \"How has AWS evolved?\"\n",
        "result = qa_chain({\"query\": query})\n",
        "print(f'Query: {result[\"query\"]}\\n')\n",
        "print(f'Result: {result[\"result\"]}\\n')\n",
        "print(f'Context Documents: ')\n",
        "for srcdoc in result[\"source_documents\"]:\n",
        "      print(f'{srcdoc}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a826123-5998-45dd-9dda-c71386c89491",
      "metadata": {
        "tags": [],
        "id": "3a826123-5998-45dd-9dda-c71386c89491"
      },
      "outputs": [],
      "source": [
        "query = \"Why is Amazon successful?\"\n",
        "result = qa_chain({\"query\": query})\n",
        "print(f'Query: {result[\"query\"]}\\n')\n",
        "print(f'Result: {result[\"result\"]}\\n')\n",
        "print(f'Context Documents: ')\n",
        "for srcdoc in result[\"source_documents\"]:\n",
        "      print(f'{srcdoc}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2418da7b-0bfc-4ef6-a64a-17b4ccb12174",
      "metadata": {
        "tags": [],
        "id": "2418da7b-0bfc-4ef6-a64a-17b4ccb12174"
      },
      "outputs": [],
      "source": [
        "query = \"What business challenges has Amazon experienced?\"\n",
        "result = qa_chain({\"query\": query})\n",
        "print(f'Query: {result[\"query\"]}\\n')\n",
        "print(f'Result: {result[\"result\"]}\\n')\n",
        "print(f'Context Documents: ')\n",
        "for srcdoc in result[\"source_documents\"]:\n",
        "      print(f'{srcdoc}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcd8bd21-c18f-43c8-bc1a-02380b4c928b",
      "metadata": {
        "id": "dcd8bd21-c18f-43c8-bc1a-02380b4c928b"
      },
      "source": [
        "# Clean up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bee483c-e1d8-499f-a707-82dafd3bd0cb",
      "metadata": {
        "id": "9bee483c-e1d8-499f-a707-82dafd3bd0cb"
      },
      "source": [
        "Uncomment the `delete_endpoint` calls to remove the resources you created."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Frank Morales created this cell on December 14, 2023; it fully allows automatically the deletion of endpoints, models, and endpoint configurations.\n",
        "\n",
        "#!pip install colab-env --upgrade\n",
        "import colab_env\n",
        "import os\n",
        "\n",
        "aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "aws_region=os.getenv(\"AWS_DEFAULT_REGION\")\n",
        "aws_output=os.getenv(\"AWS_DEFAULT_OUTPUT\")\n",
        "\n",
        "#!pip install boto3\n",
        "#aws_region = 'us-east-1'\n",
        "import boto3\n",
        "\n",
        "sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
        "\n",
        "def cleanup_sagemaker_resources(resource_name,resourceid):\n",
        "\n",
        "    if resourceid==0:\n",
        "       response=sagemaker_client.list_endpoints()\n",
        "    elif resourceid==1:\n",
        "         response=sagemaker_client.list_models()\n",
        "    elif resourceid==2:\n",
        "         response=sagemaker_client.list_endpoint_configs()\n",
        "\n",
        "    print(resource_name)\n",
        "    #resource_nametmp='%s'%resource_name[0:len(resource_name)-1]\n",
        "    #print('%sName'%resource_nametmp)\n",
        "\n",
        "    number_of_endpoints=len(response['%s'%resource_name])\n",
        "    for i in range(number_of_endpoints):\n",
        "        resource_nametmp='%s'%resource_name[0:len(resource_name)-1]\n",
        "        print('%sName'%resource_nametmp)\n",
        "        print(response['%s'%resource_name][i]['%sName'%resource_nametmp])\n",
        "\n",
        "        if resourceid==0:\n",
        "           endpoint_name=response['%s'%resource_name][i]['%sName'%resource_nametmp]\n",
        "           sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
        "        elif resourceid==1:\n",
        "           sagemaker_client.delete_model(ModelName=response['Models'][i]['ModelName'])\n",
        "        elif resourceid==2:\n",
        "           sagemaker_client.delete_endpoint_config(EndpointConfigName=response['EndpointConfigs'][i]['EndpointConfigName'])\n",
        "\n",
        "    print(\"\\n==================================\\n\")\n",
        "\n",
        "\n",
        "cleanup_sagemaker_resources('Endpoints',0)\n",
        "cleanup_sagemaker_resources('Models',1)\n",
        "cleanup_sagemaker_resources('EndpointConfigs',2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5fJ5IHWPZs_",
        "outputId": "04fce1e0-5d38-4036-aff4-d6a763637d94"
      },
      "id": "e5fJ5IHWPZs_",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Endpoints\n",
            "EndpointName\n",
            "meta-textgeneration-llama-2-7b-2023-12-25-09-36-27-212\n",
            "EndpointName\n",
            "hf-textembedding-all-minilm-l6-v2-2023-12-25-08-57-11-598\n",
            "\n",
            "==================================\n",
            "\n",
            "Models\n",
            "ModelName\n",
            "meta-textgeneration-llama-2-7b-2023-12-25-09-36-27-211\n",
            "ModelName\n",
            "meta-textgeneration-llama-2-7b-2023-12-25-09-30-35-205\n",
            "ModelName\n",
            "meta-textgeneration-llama-2-7b-2023-12-25-09-02-33-430\n",
            "ModelName\n",
            "hf-textembedding-all-minilm-l6-v2-2023-12-25-08-57-11-597\n",
            "\n",
            "==================================\n",
            "\n",
            "EndpointConfigs\n",
            "EndpointConfigName\n",
            "meta-textgeneration-llama-2-7b-2023-12-25-09-36-27-212\n",
            "EndpointConfigName\n",
            "meta-textgeneration-llama-2-7b-2023-12-25-09-30-35-207\n",
            "EndpointConfigName\n",
            "meta-textgeneration-llama-2-7b-2023-12-25-09-02-33-433\n",
            "EndpointConfigName\n",
            "hf-textembedding-all-minilm-l6-v2-2023-12-25-08-57-11-598\n",
            "\n",
            "==================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8276e6b3-788a-49f4-960e-8856dbf22a37",
      "metadata": {
        "tags": [],
        "id": "8276e6b3-788a-49f4-960e-8856dbf22a37"
      },
      "outputs": [],
      "source": [
        "#!pip install boto3\n",
        "aws_region = 'us-east-1'\n",
        "import boto3\n",
        "\n",
        "sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
        "\n",
        "#print(f'Deleting endpoint {embedding_model_endpoint_name}')\n",
        "\n",
        "# Delete embedding endpoint\n",
        "sagemaker_client.delete_endpoint(EndpointName=embedding_model_endpoint_name)\n",
        "print(sagemaker_client.list_endpoints)\n",
        "\n",
        "# Delete llm endpoint\n",
        "sagemaker_client.delete_endpoint(EndpointName=llm_model_endpoint_name)"
      ]
    }
  ],
  "metadata": {
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 20,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": true,
        "memoryGiB": 0,
        "name": "ml.geospatial.interactive",
        "supportedImageNames": [
          "sagemaker-geospatial-v1-0"
        ],
        "vcpuNum": 0
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 54,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      },
      {
        "_defaultOrder": 55,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 56,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4de.24xlarge",
        "vcpuNum": 96
      }
    ],
    "instance_type": "ml.t3.medium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1335cbce-a8a6-443d-804b-c6bc4d0d8c54",
        "582419ab-471e-4bdf-8b6a-a49c57f2a882",
        "e640ff1f-b6c5-48ae-86ab-a69b629f7c1b",
        "d7696e9d-1d95-45fb-b575-76018d08e2ac",
        "b29a7597-abc0-4a14-8d6e-810893ff4a78",
        "3fa9bd43-f485-4acd-bf4a-aa2661f3ad2b",
        "dcd8bd21-c18f-43c8-bc1a-02380b4c928b"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}